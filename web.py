import os
import inspect
import json
import shutil
import uuid
import gradio as gr
from openai import AzureOpenAI
from recognizeTextSample import get_ocr_text,get_ocr_text_from_filepath

api_base = os.getenv("AZURE_OPENAI_ENDPOINT")
api_key= os.getenv("AZURE_OPENAI_API_KEY")
api_version="2024-02-15-preview",
model_name = 'gpt-4' #Replace with model deployment name

client = AzureOpenAI(
    api_key=api_key,  
    azure_endpoint=api_base,
    api_version=api_version
)

tools = [
    {
        "type": "function",
        "function": {
            "name": "get_ocr_text",
            "description": "OCRç»Ÿä¸€è¯†åˆ«æ¥å£æ”¯æŒè¯†åˆ«å¤šç§å›¾ç‰‡ç±»å‹ï¼Œä»å›¾ç‰‡é“¾æ¥urlè¯»å–å‚æ•°",
            "parameters": {
                "type": "object",
                "properties": {
                    "url": {
                        "type": "string",
                        "description": "å›¾ç‰‡é“¾æ¥ï¼ˆé•¿åº¦ä¸è¶…è¿‡ 2048ï¼Œä¸æ”¯æŒ base64ï¼‰ã€‚ç¤ºä¾‹å€¼:https://example.png",
                    }
                },
                "required": ["url"],
            },
        },
    },
    {
        "type": "function",
        "function": {
            "name": "get_ocr_text_from_filepath",
            "description": "OCRç»Ÿä¸€è¯†åˆ«æ¥å£æ”¯æŒè¯†åˆ«å¤šç§å›¾ç‰‡ç±»å‹ï¼Œä»æ–‡ä»¶è·¯å¾„filepathè¯»å–å‚æ•°",
            "parameters": {
                "type": "object",
                "properties": {
                    "filepath": {
                        "type": "string",
                        "description": "å›¾ç‰‡è·¯å¾„ã€‚ç¤ºä¾‹å€¼:/tmp/example.png",
                    }
                },
                "required": ["filepath"],
            },
        },
    },
]
available_functions = {
    "get_ocr_text": get_ocr_text,
    "get_ocr_text_from_filepath": get_ocr_text_from_filepath
}

# helper method used to check if the correct arguments are provided to a function
def check_args(function, args):
    sig = inspect.signature(function)
    params = sig.parameters

    # Check if there are extra arguments
    for name in args:
        if name not in params:
            return False
    # Check if the required arguments are provided
    for name, param in params.items():
        if param.default is param.empty and name not in args:
            return False

    return True

def run_conversation(messages, tools, available_functions):
    # Step 1: send the conversation and available functions to GPT
    response = client.chat.completions.create(
        model=model_name,
        messages=messages,
        tools=tools,
        tool_choice="auto",
    )

    response_message = response.choices[0].message

    # Step 2: check if GPT wanted to call a function
    if response_message.tool_calls:
        print("Recommended Function call:")
        print(response_message.tool_calls[0])
        print()

        # Step 3: call the function
        # Note: the JSON response may not always be valid; be sure to handle errors

        function_name = response_message.tool_calls[0].function.name

        # verify function exists
        if function_name not in available_functions:
            return "Function " + function_name + " does not exist"
        function_to_call = available_functions[function_name]

        # verify function has correct number of arguments
        function_args = json.loads(response_message.tool_calls[0].function.arguments)
        if check_args(function_to_call, function_args) is False:
            return "Invalid number of arguments for function: " + function_name
        function_response = function_to_call(**function_args)

        print("Output of function call:")
        print(function_response)
        print()

        # Step 4: send the info on the function call and function response to GPT

        # adding assistant response to messages
        messages.append(
            {
                "role": response_message.role,
                "function_call": {
                    "name": response_message.tool_calls[0].function.name,
                    "arguments": response_message.tool_calls[0].function.arguments,
                },
                "content": None,
            }
        )

        # adding function response to messages
        messages.append(
            {
                "role": "function",
                "name": function_name,
                "content": function_response,
            }
        )  # extend conversation with function response

        print("Messages in second request:")
        for message in messages:
            print(message)
        print()

        second_response = client.chat.completions.create(
            messages=messages,
            model=model_name
        )  # get a new response from GPT where it can see the function response

        return second_response
    return response

 
def add_text(history, text):
    history = history + [(text, None)]
    return history, gr.Textbox(value="", interactive=False)

# ç›®æ ‡æ–‡ä»¶å¤¹è·¯å¾„
target_folder = "/tmp/upload/"
latest_file = []

def add_file(history, file):
    history = history + [((file.name,), None)]
    # è·å–æ–‡ä»¶åç¼€å
    source_file = file.name
    file_extension = os.path.splitext(source_file)[1]
    # ç”ŸæˆUUIDä½œä¸ºæ–°æ–‡ä»¶å
    new_filename = str(uuid.uuid4()) + file_extension
    # ç›®æ ‡æ–‡ä»¶è·¯å¾„
    target_file = os.path.join(target_folder, new_filename)
    # å¤åˆ¶æ–‡ä»¶å¹¶é‡å‘½å
    shutil.copy(source_file, target_file)
    latest_file.append(target_file)
    return history

messages = [] 
def bot(history):
    if len(messages) == 0:
        messages.append( {
            "role": "system",
            "content": "Assistant is a helpful assistant that helps users get answers to questions. Assistant has access to several tools and sometimes you may need to call multiple tools in sequence to get answers for your users.ç”¨ä¸­æ–‡å›ç­”",
            })
 
    
    messages.append({
        "role": "user",
        "content": f"è¯†åˆ«å›¾ç‰‡filepath={latest_file[0]}" if len(latest_file)>0 else history[-1][0]
    })
    assistant_response = run_conversation(messages, tools, available_functions)
    latest_file.clear();
    history[-1][1] = assistant_response.choices[0].message.content;
    return history

def clear_history(history, *args):
    history = []
    messages.clear()
    print("æ–°ä¼šè¯")
    return history, gr.Textbox(value="")

if __name__ == '__main__':
    with gr.Blocks() as demo:
        chatbot = gr.Chatbot(
            [],
            elem_id="chatbot",
            bubble_full_width=False,
            avatar_images=(None, (os.path.join(os.path.dirname(__file__), "avatar.jpg"))),
        )

        with gr.Row():
            txt = gr.Textbox(
                scale=4,
                show_label=False,
                placeholder="è¾“å…¥æ–‡æœ¬å¹¶æŒ‰å›è½¦é”®ï¼Œæˆ–ä¸Šä¼ å›¾åƒ",
                container=False,
            )
            btn = gr.UploadButton("ğŸ“", file_types=["image"])
            clear = gr.ClearButton([chatbot, txt])

        txt_msg = txt.submit(add_text, [chatbot, txt], [chatbot, txt], queue=False).then(
            bot, chatbot, chatbot, api_name="bot_response"
        )
        txt_msg.then(lambda: gr.Textbox(interactive=True), None, [txt], queue=False)
        file_msg = btn.upload(add_file, [chatbot, btn], [chatbot], queue=False).then(
            bot, chatbot, chatbot
        )
        clear.click(clear_history, [chatbot, txt], [chatbot, txt], queue=False)
    demo.queue().launch(share=True)



